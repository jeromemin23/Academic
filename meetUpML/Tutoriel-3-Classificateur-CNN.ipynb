{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificateur CNN\n",
    "\n",
    "Dans ce tutoriel, nous allons designer un réseau à convolution pour faire de la classification d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets.cifar import CIFAR100\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from pytoune.framework import Model, ModelCheckpoint, Callback, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from pytoune import torch_to_numpy\n",
    "from pytoune.layers import Flatten\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "n_epoch = 5\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100(download=False, path='./data', transform=None):\n",
    "    \"\"\"Loads the cifar100 dataset.\n",
    "\n",
    "    :param download: Download the dataset\n",
    "    :param path: Folder to put the dataset\n",
    "    :return: The train and test dataset\n",
    "    \"\"\"\n",
    "    train_dataset = CIFAR100(path, train=True, download=download, transform=transform)\n",
    "    test_dataset = CIFAR100(path, train=False, download=download, transform=transform)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def load_cifar100_with_validation_set(download=False, path='./data', train_split=0.8):\n",
    "    \"\"\"Loads the CIFAR10 dataset.\n",
    "\n",
    "    :param download: Download the dataset\n",
    "    :param path: Folder to put the dataset\n",
    "    :return: The train, valid and test dataset ready to be ingest in a neural network\n",
    "    \"\"\"\n",
    "    norm_coefs = {}\n",
    "    norm_coefs['imagenet'] = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*norm_coefs['imagenet'])\n",
    "    ])\n",
    "    train, test = load_cifar100(download, path, transform=transform)\n",
    "    lengths = [round(train_split*len(train)), round((1.0-train_split)*len(train))]\n",
    "    train, valid = random_split(train, lengths)\n",
    "    return train, valid, test\n",
    "  \n",
    "def count_number_of_parameters(net):\n",
    "    return sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = load_cifar100_with_validation_set(download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid, batch_size=batch_size)\n",
    "test_loader = DataLoader(test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name, pytorch_module, params=None):\n",
    "    if not params:\n",
    "      params = pytorch_module.parameters()\n",
    "\n",
    "    optimizer = optim.SGD(params, lr=learning_rate)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5)\n",
    "    lr_scheduler = ReduceLROnPlateau(patience=2)\n",
    "    callbacks = [early_stopping, lr_scheduler]\n",
    "\n",
    "    # Pytoune Model\n",
    "    model = Model(pytorch_module, optimizer, loss_function, metrics=['accuracy'])\n",
    "\n",
    "    # Send model on GPU\n",
    "    model.to(device)\n",
    "\n",
    "    # Train\n",
    "    model.fit_generator(train_loader, valid_loader, epochs=n_epoch)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our convolutional model\n",
    "class CifarNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 50, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(50, 150, 3, padding=1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm2d(10)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(50)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(150)\n",
    "        \n",
    "        self.fc1 = nn.Linear(150 * 56 * 56, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 3, 224, 224)\n",
    "        x = F.max_pool2d(F.relu(self.batchnorm1(self.conv1(x))), (2, 2))\n",
    "        # x shape: (batch_size, 10, 112, 112)\n",
    "        x = F.max_pool2d(F.relu(self.batchnorm2(self.conv2(x))), (2, 2))\n",
    "        # x shape: (batch_size, 50, 56, 56)\n",
    "        x = F.relu(self.batchnorm3(self.conv3(x)))\n",
    "        # x shape: (batch_size, 150, 56, 56)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # x shape: (batch_size, 470400)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 118.37s Step 1250/1250: loss: 4.469712, acc: 11.855000, val_loss: 3.543773, val_acc: 17.420000\n",
      "Epoch 2/5 165.64s Step 1250/1250: loss: 3.249558, acc: 23.327500, val_loss: 3.229298, val_acc: 24.000000\n",
      "Epoch 3/5 190.28s Step 1250/1250: loss: 2.748987, acc: 33.047500, val_loss: 3.138871, val_acc: 26.580000\n",
      "Epoch 4/5 188.58s Step 1250/1250: loss: 2.174158, acc: 45.277500, val_loss: 3.294137, val_acc: 26.450000\n",
      "Epoch 5/5 195.99s Step 1250/1250: loss: 1.577077, acc: 59.297500, val_loss: 3.471613, val_acc: 26.730000\n"
     ]
    }
   ],
   "source": [
    "net = CifarNet()\n",
    "model = train('simple_cnn', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.442967367553711, 26.25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47113000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_number_of_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Same model as above using the sequential module of Pytorch\n",
    "model = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('conv1', nn.Conv2d(3, 10, 3, padding=1)),\n",
    "        ('bn1', nn.BatchNorm2d(10)),\n",
    "        ('relu1', nn.ReLU()),\n",
    "        ('maxpool1', nn.MaxPool2d(2)),\n",
    "        ('conv2', nn.Conv2d(10, 50, 3, padding=1)),\n",
    "        ('bn1', nn.BatchNorm2d(50)),\n",
    "        ('relu2', nn.ReLU()),\n",
    "        ('maxpool2', nn.MaxPool2d(2)),\n",
    "        ('conv3', nn.Conv2d(50, 150, 3, padding=1)),\n",
    "        ('bn1', nn.BatchNorm2d(150)),\n",
    "        ('relu3', nn.ReLU()),\n",
    "        ('fc1', nn.Linear(150 * 56 * 56, num_classes))\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
